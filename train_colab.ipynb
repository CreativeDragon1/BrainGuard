{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alzheimer's MRI Detection Model Training\n",
    "## Google Colab Notebook\n",
    "\n",
    "This notebook trains a deep learning model to detect Alzheimer's disease from MRI scans.\n",
    "Run the cells in order to train and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Quick Setup Guide\n",
    "\n",
    "**Before running this notebook:**\n",
    "1. Upload your dataset to Colab (see Step 4 for details)\n",
    "2. Run cells in order from top to bottom\n",
    "3. Models will be saved automatically during training\n",
    "4. Download trained models from Step 11\n",
    "\n",
    "**Dataset Structure Required:**\n",
    "```\n",
    "BrainGuard/Assets/Datasets/MRI Dataset/\n",
    "â”œâ”€â”€ train.parquet\n",
    "â””â”€â”€ test.parquet (optional)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clone Repository and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CreativeDragon1/BrainGuard.git\n",
    "%cd BrainGuard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q pandas scikit-learn pillow tqdm\n",
    "!pip install -q matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ“ All imports successful\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SEED = 42\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import Models and Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn_model import AlzheimersCNN, ResNetModel, SimpleResNet\n",
    "print(\"âœ“ Model architectures imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "class ParquetMRIDataset(Dataset):\n",
    "    def __init__(self, records, labels, train=True):\n",
    "        self.records = records\n",
    "        self.labels = labels\n",
    "        self.train = train\n",
    "        self.base_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "        ])\n",
    "        self.aug = transforms.Compose([\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw = self.records[idx]\n",
    "        img = Image.open(io.BytesIO(raw)).convert('L')\n",
    "        if self.train:\n",
    "            img = self.aug(img)\n",
    "        img = self.base_transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "print(\"âœ“ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Upload and Prepare Dataset\n",
    "\n",
    "**IMPORTANT:** Before proceeding, upload your parquet files using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"ðŸ“¤ Click 'Choose Files' and upload: train.parquet and test.parquet\")\n",
    "print(\"   Tip: Hold Cmd/Ctrl + Click to select multiple files\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "os.makedirs('Assets/Datasets/MRI Dataset', exist_ok=True)\n",
    "\n",
    "for file in uploaded:\n",
    "    if file.endswith('.parquet'):\n",
    "        dest = f'Assets/Datasets/MRI Dataset/{file}'\n",
    "        shutil.move(file, dest)\n",
    "        print(f\"âœ“ {file} ready for training\")\n",
    "\n",
    "print(\"\\nâœ“ Dataset upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('Assets/Datasets/MRI Dataset/train.parquet')\n",
    "test_path = Path('Assets/Datasets/MRI Dataset/test.parquet')\n",
    "\n",
    "if not train_path.exists():\n",
    "    print(\"âŒ train.parquet not found! Please run Step 4\")\n",
    "else:\n",
    "    df_train = pd.read_parquet(train_path)\n",
    "    print(f\"âœ“ Training data: {len(df_train)} samples\")\n",
    "    print(df_train['label'].value_counts())\n",
    "    \n",
    "    df_test = pd.read_parquet(test_path) if test_path.exists() else None\n",
    "    if df_test is not None:\n",
    "        print(f\"\\nâœ“ Test data: {len(df_test)} samples\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No test set found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records = [row['image']['bytes'] for _, row in df_train.iterrows()]\n",
    "train_labels = df_train['label'].tolist()\n",
    "\n",
    "indices = np.arange(len(train_records))\n",
    "np.random.shuffle(indices)\n",
    "val_split = int(0.1 * len(indices))\n",
    "\n",
    "def subset(records, labels, idxs):\n",
    "    return [records[i] for i in idxs], [labels[i] for i in idxs]\n",
    "\n",
    "tr_recs, tr_labs = subset(train_records, train_labels, indices[val_split:])\n",
    "val_recs, val_labs = subset(train_records, train_labels, indices[:val_split])\n",
    "\n",
    "train_ds = ParquetMRIDataset(tr_recs, tr_labs, train=True)\n",
    "val_ds = ParquetMRIDataset(val_recs, val_labs, train=False)\n",
    "test_ds = ParquetMRIDataset([row['image']['bytes'] for _, row in df_test.iterrows()], df_test['label'].tolist(), train=False) if df_test is not None else None\n",
    "\n",
    "print(f\"âœ“ Train: {len(train_ds)}, Val: {len(val_ds)}\", end=\"\")\n",
    "if test_ds:\n",
    "    print(f\", Test: {len(test_ds)}\")\n",
    "else:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create Data Loaders and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, EPOCHS, LR = 32, 50, 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2) if test_ds else None\n",
    "\n",
    "print(f\"âœ“ Loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader=None, epochs=50, lr=1e-3, model_name='model'):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.epochs = epochs\n",
    "        self.model_name = model_name\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=5)\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'learning_rate': []}\n",
    "        self.best_val_acc = 0\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = correct = total = 0\n",
    "        for images, labels in tqdm(self.train_loader, desc='Train'):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return total_loss / len(self.train_loader), correct / total\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = correct = total = 0\n",
    "        all_preds = all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.val_loader, desc='Val'):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        return total_loss / len(self.val_loader), correct / total, all_preds, all_labels\n",
    "    \n",
    "    def test(self):\n",
    "        if self.test_loader is None: return None\n",
    "        self.model.eval()\n",
    "        correct = total = 0\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.test_loader, desc='Test'):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "        return {'accuracy': correct/total, 'predictions': all_preds}\n",
    "    \n",
    "    def train(self):\n",
    "        print(f\"Training {self.model_name} on {DEVICE}\")\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            val_loss, val_acc, _, _ = self.validate()\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['learning_rate'].append(self.optimizer.param_groups[0]['lr'])\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}: TL={train_loss:.4f} TA={train_acc:.4f} VL={val_loss:.4f} VA={val_acc:.4f}\")\n",
    "            self.scheduler.step(val_loss)\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.save_checkpoint('best')\n",
    "        return self.history\n",
    "    \n",
    "    def save_checkpoint(self, name='model'):\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        path = f'models/best_{self.model_name}.pth' if name == 'best' else f'models/{self.model_name}_{name}.pth'\n",
    "        torch.save({'model_state_dict': self.model.state_dict(), 'history': self.history, 'best_val_acc': self.best_val_acc}, path)\n",
    "        print(f\"âœ“ Saved to {path}\")\n",
    "\n",
    "print(\"âœ“ Trainer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetModel(pretrained=True, num_classes=4)\n",
    "trainer = Trainer(model, train_loader, val_loader, test_loader, epochs=EPOCHS, lr=LR, model_name='resnet')\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_loader:\n",
    "    results = trainer.test()\n",
    "    print(f\"\\nâœ“ Test Accuracy: {results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Visualize and Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax2.plot(history['train_acc'], label='Train Acc')\n",
    "ax2.plot(history['val_acc'], label='Val Acc')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png')\n",
    "plt.show()\n",
    "print(\"âœ“ Plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"ðŸ“¥ Downloading trained models...\\n\")\n",
    "for f in os.listdir('models'):\n",
    "    if f.endswith('.pth'):\n",
    "        size = os.path.getsize(f'models/{f}') / (1024*1024)\n",
    "        print(f\"  Downloading: {f} ({size:.1f}MB)\")\n",
    "        files.download(f'models/{f}')\n",
    "\n",
    "print(\"\\nðŸ“¥ Downloading metrics...\")\n",
    "files.download('training_results.png')\n",
    "\n",
    "# Save history\n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump({k: [float(x) for x in v] for k, v in history.items()}, f, indent=2)\n",
    "files.download('training_metrics.json')\n",
    "\n",
    "print(\"\\nâœ… All files downloaded!\")\n",
    "print(f\"\\nBest Validation Accuracy: {trainer.best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Training Complete!\n",
    "\n",
    "### How to Use Downloaded Models\n",
    "\n",
    "**1. Place model files in your local repo:**\n",
    "```\n",
    "BrainGuard/models/\n",
    "â”œâ”€â”€ best_resnet.pth\n",
    "â””â”€â”€ ...\n",
    "```\n",
    "\n",
    "**2. Load and use:**\n",
    "```python\n",
    "import torch\n",
    "from models.cnn_model import ResNetModel\n",
    "\n",
    "model = ResNetModel(pretrained=False, num_classes=4)\n",
    "checkpoint = torch.load('models/best_resnet.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Use for predictions\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "    prediction = torch.argmax(output)\n",
    "```\n",
    "\n",
    "### Files Downloaded\n",
    "- `best_resnet.pth` - Best model from training\n",
    "- `training_results.png` - Loss & Accuracy plots\n",
    "- `training_metrics.json` - Training history data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n",
  "language_info": {\n",
   "name": "python",\n",
   "version": "3.10.0"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n,}\n",
