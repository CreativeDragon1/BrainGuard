{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Alzheimer's MRI Detection - Colab Training\n",
        "## Train models and download them locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Clone & Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/CreativeDragon1/BrainGuard.git\n",
        "%cd BrainGuard\n",
        "!pip install -q torch torchvision torchaudio pandas scikit-learn pillow tqdm matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Upload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, shutil\n",
        "\n",
        "print('Click Choose Files and upload: train.parquet and test.parquet')\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.makedirs('Assets/Datasets/MRI Dataset', exist_ok=True)\n",
        "for f in uploaded:\n",
        "    if f.endswith('.parquet'):\n",
        "        shutil.move(f, f'Assets/Datasets/MRI Dataset/{f}')\n",
        "        print(f'\u2713 {f} ready')\n",
        "print('Dataset uploaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Import & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd, io, json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from models.cnn_model import ResNetModel\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Define Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, records, labels, train=True):\n",
        "        self.records = records\n",
        "        self.labels = labels\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(io.BytesIO(self.records[idx])).convert('L')\n",
        "        img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "print('Dataset class ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, test_loader=None, epochs=50, lr=1e-3):\n",
        "        self.model = model.to(DEVICE)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.epochs = epochs\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "    \n",
        "    def train_epoch(self):\n",
        "        self.model.train()\n",
        "        loss_total = acc_total = count = 0\n",
        "        for imgs, lbls in tqdm(self.train_loader, desc='Train'):\n",
        "            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
        "            self.optimizer.zero_grad()\n",
        "            out = self.model(imgs)\n",
        "            loss = self.criterion(out, lbls)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            loss_total += loss.item()\n",
        "            acc_total += (out.argmax(1) == lbls).sum().item()\n",
        "            count += lbls.size(0)\n",
        "        return loss_total / len(self.train_loader), acc_total / count\n",
        "    \n",
        "    def val(self):\n",
        "        self.model.eval()\n",
        "        loss_total = acc_total = count = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, lbls in tqdm(self.val_loader, desc='Val'):\n",
        "                imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
        "                out = self.model(imgs)\n",
        "                loss = self.criterion(out, lbls)\n",
        "                loss_total += loss.item()\n",
        "                acc_total += (out.argmax(1) == lbls).sum().item()\n",
        "                count += lbls.size(0)\n",
        "        return loss_total / len(self.val_loader), acc_total / count\n",
        "    \n",
        "    def train(self):\n",
        "        for ep in range(self.epochs):\n",
        "            tl, ta = self.train_epoch()\n",
        "            vl, va = self.val()\n",
        "            self.history['train_loss'].append(tl)\n",
        "            self.history['val_loss'].append(vl)\n",
        "            self.history['train_acc'].append(ta)\n",
        "            self.history['val_acc'].append(va)\n",
        "            print(f'Ep {ep+1}/{self.epochs}: TL={tl:.4f} TA={ta:.4f} VL={vl:.4f} VA={va:.4f}')\n",
        "        self.save_model()\n",
        "    \n",
        "    def save_model(self):\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "        torch.save(self.model.state_dict(), 'models/best_resnet.pth')\n",
        "        print('Model saved!')\n",
        "\n",
        "print('Trainer ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Load Data & Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = Path('Assets/Datasets/MRI Dataset/train.parquet')\n",
        "test_path = Path('Assets/Datasets/MRI Dataset/test.parquet')\n",
        "\n",
        "df_train = pd.read_parquet(train_path)\n",
        "df_test = pd.read_parquet(test_path) if test_path.exists() else None\n",
        "\n",
        "print(f'Train: {len(df_train)}, Test: {len(df_test) if df_test is not None else 0}')\n",
        "\n",
        "train_recs = [r['image']['bytes'] for _, r in df_train.iterrows()]\n",
        "train_lbls = df_train['label'].tolist()\n",
        "\n",
        "idx = np.arange(len(train_recs))\n",
        "np.random.shuffle(idx)\n",
        "split = int(0.1 * len(idx))\n",
        "\n",
        "train_ds = MRIDataset([train_recs[i] for i in idx[split:]], [train_lbls[i] for i in idx[split:]])\n",
        "val_ds = MRIDataset([train_recs[i] for i in idx[:split]], [train_lbls[i] for i in idx[:split]])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print('Data ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ResNetModel(pretrained=True, num_classes=4)\n",
        "trainer = Trainer(model, train_loader, val_loader, epochs=50, lr=1e-3)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print('Downloading model...')\n",
        "files.download('models/best_resnet.pth')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainer.history['train_loss'], label='Train')\n",
        "plt.plot(trainer.history['val_loss'], label='Val')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(trainer.history['train_acc'], label='Train')\n",
        "plt.plot(trainer.history['val_acc'], label='Val')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_results.png')\n",
        "plt.show()\n",
        "\n",
        "files.download('training_results.png')\n",
        "print('Done!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}